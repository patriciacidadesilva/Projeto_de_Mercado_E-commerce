# ğŸ Dia 2: Python & IngestÃ£o de Dados | Jornada de Dados

Bem-vindo ao **segundo dia da imersÃ£o Jornada de Dados**! Hoje vocÃª vai aprender Python para trabalhar com dados, focando em **ingestÃ£o** - o processo de coletar dados de diferentes fontes e preparÃ¡-los para anÃ¡lise.

---

## ğŸ“– O que Ã© Python para Dados?

**Python** Ã© uma linguagem de programaÃ§Ã£o versÃ¡til e poderosa que se tornou o padrÃ£o da indÃºstria para trabalhar com dados. Ã‰ a ferramenta que permite:

- âœ… **Ingerir dados** - Coletar dados de APIs, arquivos externos, bancos de dados, Data Lakes
- âœ… **Processar dados** - Limpar, transformar e preparar dados para anÃ¡lise
- âœ… **Analisar dados** - Fazer anÃ¡lises estatÃ­sticas e exploratÃ³rias
- âœ… **Automatizar tarefas** - Criar scripts que fazem o trabalho pesado

**Python nÃ£o Ã© apenas uma linguagem de programaÃ§Ã£o.** Ã‰ um ecossistema completo com bibliotecas especializadas para cada necessidade de dados.

---

## ğŸ”„ Processo de IngestÃ£o de Dados

**Ontem (Dia 1 - SQL):** Trabalhamos com dados que **jÃ¡ existiam** no banco de dados (4 tabelas: produtos, clientes, vendas, preco_competidores).

**Hoje (Dia 2 - Python):** Vamos **trazer novos dados** para o banco atravÃ©s do Python, coletando dados de diferentes fontes externas.

### ğŸ“Š Fluxo de IngestÃ£o de Dados

O diagrama abaixo mostra como Python atua como **ponte** entre diferentes fontes de dados e o banco SQL:

```mermaid
graph TB
    subgraph "ğŸŒ Fontes de Dados Externas"
        API[ğŸ“¡ APIs REST<br/>Bitcoin, NASA, etc]
        ARQ[ğŸ“ Arquivos Externos<br/>GitHub, S3, URLs]
        BANCO[ğŸ—„ï¸ Outros Bancos<br/>PostgreSQL, MySQL]
        LAKE[ğŸ’¾ Data Lakes<br/>S3, Azure, GCS]
        SISTEMA[âš™ï¸ Sistemas<br/>ERP, CRM, etc]
    end
    
    subgraph "ğŸ Python - IngestÃ£o"
        EXTRAIR[ğŸ“¥ Extrair Dados]
        TRANSFORMAR[ğŸ”„ Transformar/Limpar]
        VALIDAR[âœ… Validar Dados]
    end
    
    subgraph "ğŸ—„ï¸ Banco de Dados SQL"
        PRODUTOS[(ğŸ“¦ produtos)]
        CLIENTES[(ğŸ‘¥ clientes)]
        VENDAS[(ğŸ’° vendas)]
        CONCORRENTES[(ğŸª preco_competidores)]
        NOVOS_DADOS[(ğŸ†• novos_dados)]
    end
    
    API -->|requests.get| EXTRAIR
    ARQ -->|requests + pandas| EXTRAIR
    BANCO -->|sqlalchemy| EXTRAIR
    LAKE -->|boto3/pyarrow| EXTRAIR
    SISTEMA -->|API/arquivos| EXTRAIR
    
    EXTRAIR --> TRANSFORMAR
    TRANSFORMAR --> VALIDAR
    VALIDAR -->|pandas.to_sql| PRODUTOS
    VALIDAR -->|pandas.to_sql| CLIENTES
    VALIDAR -->|pandas.to_sql| VENDAS
    VALIDAR -->|pandas.to_sql| CONCORRENTES
    VALIDAR -->|pandas.to_sql| NOVOS_DADOS
    
    style API fill:#4A90E2,color:#fff
    style ARQ fill:#FF6B6B,color:#fff
    style BANCO fill:#FFA500,color:#fff
    style LAKE fill:#9B59B6,color:#fff
    style SISTEMA fill:#1ABC9C,color:#fff
    style EXTRAIR fill:#E74C3C,color:#fff
    style TRANSFORMAR fill:#F39C12,color:#fff
    style VALIDAR fill:#27AE60,color:#fff
    style PRODUTOS fill:#3498DB,color:#fff
    style CLIENTES fill:#3498DB,color:#fff
    style VENDAS fill:#3498DB,color:#fff
    style CONCORRENTES fill:#3498DB,color:#fff
    style NOVOS_DADOS fill:#2ECC71,color:#fff
```

### ğŸ¯ Exemplo PrÃ¡tico: IntegraÃ§Ã£o de Dados Externos

**Caso de NegÃ³cio:** Coletar dados de produtos e preÃ§os de arquivos pÃºblicos (GitHub, S3) para anÃ¡lise competitiva.

**Fluxo:**
1. ğŸ“ **Arquivos Externos** â†’ Python baixa dados de repositÃ³rios pÃºblicos (Parquet, CSV)
2. ğŸ”„ **TransformaÃ§Ã£o** â†’ Limpa e padroniza dados
3. âœ… **ValidaÃ§Ã£o** â†’ Verifica qualidade dos dados
4. ğŸ—„ï¸ **Carga** â†’ Salva na tabela `preco_competidores` do banco SQL
5. ğŸ“Š **AnÃ¡lise** â†’ SQL compara nossos preÃ§os com concorrentes

**Resultado:** Dados atualizados de concorrentes prontos para anÃ¡lise no banco SQL!

### ğŸ“š Principais Bibliotecas Python para Dados

| Biblioteca | Logo | DescriÃ§Ã£o | GitHub |
|------------|------|-----------|--------|
| **Pandas** | ğŸ¼ | ManipulaÃ§Ã£o e anÃ¡lise de dados tabulares | [pandas-dev/pandas](https://github.com/pandas-dev/pandas) |
| **PySpark** | âš¡ | Processamento distribuÃ­do de Big Data | [apache/spark](https://github.com/apache/spark) |
| **Airflow** | âœˆï¸ | OrquestraÃ§Ã£o e agendamento de pipelines | [apache/airflow](https://github.com/apache/airflow) |
| **Streamlit** | ğŸˆ | CriaÃ§Ã£o rÃ¡pida de dashboards e apps web | [streamlit/streamlit](https://github.com/streamlit/streamlit) |
| **NumPy** | ğŸ”¢ | ComputaÃ§Ã£o numÃ©rica e arrays multidimensionais | [numpy/numpy](https://github.com/numpy/numpy) |
| **Scikit-learn** | ğŸ¤– | Machine Learning e anÃ¡lise de dados | [scikit-learn/scikit-learn](https://github.com/scikit-learn/scikit-learn) |
| **Matplotlib** | ğŸ“Š | VisualizaÃ§Ã£o de dados e grÃ¡ficos | [matplotlib/matplotlib](https://github.com/matplotlib/matplotlib) |
| **Requests** | ğŸŒ | RequisiÃ§Ãµes HTTP e consumo de APIs | [psf/requests](https://github.com/psf/requests) |
| **PyArrow** | ğŸ¹ | Leitura/escrita de Parquet e formatos colunares | [apache/arrow](https://github.com/apache/arrow) |
| **SQLAlchemy** | ğŸ—„ï¸ | ORM e acesso a bancos de dados | [sqlalchemy/sqlalchemy](https://github.com/sqlalchemy/sqlalchemy) |

**Cada biblioteca resolve um problema especÃ­fico:**
- ğŸ¼ **Pandas**: Trabalhar com dados tabulares (CSV, Excel, SQL)
- âš¡ **PySpark**: Processar grandes volumes de dados distribuÃ­dos
- âœˆï¸ **Airflow**: Orquestrar e agendar pipelines de dados
- ğŸˆ **Streamlit**: Criar dashboards interativos rapidamente
- ğŸ”¢ **NumPy**: OperaÃ§Ãµes matemÃ¡ticas e arrays eficientes
- ğŸ¤– **Scikit-learn**: Machine Learning e modelos preditivos
- ğŸ“Š **Matplotlib**: Visualizar dados com grÃ¡ficos
- ğŸŒ **Requests**: Consumir APIs e fazer requisiÃ§Ãµes HTTP
- ğŸ¹ **PyArrow**: Trabalhar com arquivos Parquet (formato otimizado para Big Data)
- ğŸ—„ï¸ **SQLAlchemy**: Conectar e trabalhar com bancos de dados

**Exemplo:**
```python
# VocÃª diz: "Quero ler dados de vendas e calcular receita total"
import pandas as pd

df = pd.read_csv("vendas.csv")
df['receita'] = df['quantidade'] * df['preco_unitario']
receita_total = df['receita'].sum()

print(f"Receita total: R$ {receita_total:,.2f}")
```

---

## ğŸ’¼ Mercado de Python para Dados

Python Ã© a linguagem mais usada no mercado de dados e ciÃªncia de dados:

### ğŸ“Š Por que Python Ã© importante?

1. **Ecossistema rico**: Pandas, NumPy, Scikit-learn, TensorFlow, PyTorch
2. **Demanda de mercado**: Habilidade essencial em 90% das vagas de dados
3. **Versatilidade**: Serve para anÃ¡lise, engenharia, machine learning, automaÃ§Ã£o
4. **Comunidade**: Grande comunidade, muitos recursos e bibliotecas open-source
5. **IntegraÃ§Ã£o**: FÃ¡cil integraÃ§Ã£o com bancos de dados, APIs, sistemas

### ğŸ¯ Onde Python Ã© usado?

- **Data Engineering**: Pipelines de dados, ETL, ingestÃ£o
- **Data Analysis**: AnÃ¡lise exploratÃ³ria, relatÃ³rios automatizados
- **Data Science**: Machine Learning, estatÃ­stica, modelagem
- **AutomaÃ§Ã£o**: Scripts para tarefas repetitivas
- **APIs e IntegraÃ§Ãµes**: Conectar diferentes sistemas

### ğŸ’° SalÃ¡rios no Brasil (2024)

- **Analista de Dados JÃºnior**: R$ 3.000 - R$ 6.000
- **Analista de Dados Pleno**: R$ 6.000 - R$ 10.000
- **Analista de Dados SÃªnior**: R$ 10.000 - R$ 18.000
- **Cientista de Dados**: R$ 8.000 - R$ 20.000+
- **Engenheiro de Dados**: R$ 10.000 - R$ 25.000+

**Python Ã© a base de todas essas carreiras.**

**Pesquisa de Vagas:**
- ğŸ” [LinkedIn: Python & SQL no Brasil](https://www.linkedin.com/jobs/search/?currentJobId=4350781561&geoId=106057199&keywords=python%20%26%20sql&origin=JOB_SEARCH_PAGE_SEARCH_BUTTON&refresh=true) - **13.000+ vagas disponÃ­veis**

**Fonte:** Glassdoor, LinkedIn, pesquisas de mercado 2024

---

## ğŸ¯ Foco do Curso

Neste **Dia 2**, vamos focar em:

âœ… **IngestÃ£o de Dados** - 70% do tempo  
âœ… **Tratamento BÃ¡sico** - 20% do tempo  
âœ… **ExportaÃ§Ã£o** - 10% do tempo  

**Por quÃª?** Engenheiros e analistas de dados passam a maior parte do tempo coletando e preparando dados. VocÃª vai aprender a **pensar como engenheiro de dados** e **integrar diferentes fontes de dados**.

---

## ğŸ”„ SQL vs Python: Qual a DiferenÃ§a?

### ğŸ“Š SQL (Dia 1)
**Trabalha com dados que JÃ EXISTEM no banco de dados**

- âœ… Dados jÃ¡ estÃ£o armazenados
- âœ… Foco em consultar e analisar
- âœ… Linguagem declarativa (diz o que quer)
- âœ… Otimizado para grandes volumes
- âœ… Ideal para anÃ¡lises e relatÃ³rios

**Exemplo:**
```sql
-- Os dados JÃ ESTÃƒO no banco
SELECT * FROM vendas WHERE data_venda > '2024-01-01';
```

### ğŸ Python (Dia 2)
**BUSCA dados de sistemas externos e integra diferentes fontes**

- âœ… Dados vÃªm de sistemas externos (APIs, arquivos externos, Data Lakes)
- âœ… Foco em coletar e integrar
- âœ… Linguagem imperativa (diz como fazer)
- âœ… Ideal para automaÃ§Ã£o e integraÃ§Ã£o
- âœ… Conecta diferentes sistemas

**Exemplo:**
```python
# BUSCA dados de uma API externa
import requests
dados = requests.get("https://api.coinbase.com/v2/prices/spot").json()
```

### ğŸ¯ Resumo

| Aspecto | SQL | Python |
|---------|-----|--------|
| **Dados** | JÃ¡ existem no banco | Busca de sistemas externos |
| **Foco** | Consultar e analisar | Coletar e integrar |
| **Uso** | AnÃ¡lises e relatÃ³rios | APIs, scraping, automaÃ§Ã£o |
| **Quando usar** | Dados jÃ¡ armazenados | Dados externos, integraÃ§Ã£o |

**Python na engenharia de dados = COMUNICAR e INTEGRAR sistemas externos!**

---

## ğŸ¯ Perguntas de NegÃ³cio que Vamos Responder

Este **Dia 2** foi criado para resolver problemas reais de ingestÃ£o de dados. Abaixo estÃ£o todas as perguntas que vamos responder com os exemplos:

### ğŸ”¥ Exemplo 00: Aquecimento Python
1. **Por que preciso saber Python bÃ¡sico para trabalhar com dados?**
   - VariÃ¡veis, listas, dicionÃ¡rios - fundamentos essenciais
   - Como estruturas de dados se relacionam com dados reais
   - Por que isso Ã© a base para trabalhar com APIs e arquivos

### ğŸ’¾ Exemplo 01: Conectar com DataLake
2. **Como ler dados de um Data Lake usando a API S3?**
   - O que Ã© um Data Lake e por que Ã© importante
   - Como usar boto3 para conectar com S3/Supabase Storage
   - Como ler arquivos Parquet de Data Lakes
   - Por que AWS S3 Ã© o padrÃ£o da indÃºstria

### ğŸ—„ï¸ Exemplo 02: Salvar no Banco de Dados
3. **Como salvar dados processados em um banco PostgreSQL?**
   - Como conectar Python com PostgreSQL usando SQLAlchemy
   - Como salvar DataFrame em tabela SQL
   - Por que pandas serve para ler, processar E salvar dados

### ğŸ¯ Exemplo 03: Projeto Completo
4. **Como fazer um pipeline completo: DataLake â†’ Banco?**
   - Como combinar todos os conceitos aprendidos
   - Pipeline completo: ler do DataLake e salvar no banco
   - Fluxo EL (Extract, Load) sem processamento

### ğŸŒ Exemplo 04: Ler API Bitcoin
5. **Como obter dados de uma API e salvar no banco de dados?**
   - O que Ã© uma API e por que usar
   - Como usar a biblioteca requests
   - Como fazer requisiÃ§Ãµes GET para APIs REST
   - Pipeline completo: API â†’ Processamento â†’ Banco

---

## ğŸ”¥ Bloco 1: Aquecimento Python (20min)

Antes de trabalhar com dados, Ã© essencial dominar os fundamentos de Python. Este bloco garante que vocÃª tenha a base necessÃ¡ria.

**Conceito:** Fundamentos de Python  
**Pergunta de NegÃ³cio:** Por que preciso saber Python bÃ¡sico para trabalhar com dados?  

**O que vocÃª aprende:**
- Print e Hello World
- VariÃ¡veis e tipos bÃ¡sicos (str, int)
- Estruturas de dados (lista, dicionÃ¡rio)
- Por que isso Ã© importante para trabalhar com dados
- Como estruturas de dados se relacionam com dados reais (exemplo: tÃªnis)

**Conceitos Python:**
- `print()`: exibir informaÃ§Ãµes
- VariÃ¡veis: `str`, `int`
- Listas: `[]` - coleÃ§Ã£o ordenada de itens
- DicionÃ¡rios: `{}` - pares chave-valor (estrutura mais comum para dados tabulares)
- Lista de dicionÃ¡rios: estrutura ideal para dados estruturados

**Por que Ã© importante?**
- APIs retornam dados em JSON (que sÃ£o dicionÃ¡rios em Python)
- Arquivos externos precisam ser baixados e processados
- Pandas usa esses conceitos por baixo dos panos
- DicionÃ¡rios sÃ£o a base para trabalhar com dados estruturados

**Resultado Esperado:**
- CompreensÃ£o dos fundamentos de Python
- Capacidade de trabalhar com listas e dicionÃ¡rios
- Entendimento de como estruturas de dados se relacionam com dados reais

---

### ğŸ’¾ Exemplo 01: Conectar com DataLake

#### `exemplo-01-ler-datalake-parquet.py`

---

## ğŸ¯ ProgressÃ£o de Aprendizado

A aula estÃ¡ organizada em **5 exemplos prÃ¡ticos** que cobrem todo o fluxo de ingestÃ£o de dados:

1. **ğŸ”¥ Exemplo 00: Aquecimento Python** - Fundamentos essenciais
2. **ğŸ’¾ Exemplo 01: Conectar com DataLake** - Trabalhar com armazenamento em nuvem
3. **ğŸ—„ï¸ Exemplo 02: Salvar no Banco de Dados** - Persistir dados processados
4. **ğŸ¯ Exemplo 03: Projeto Completo** - Pipeline DataLake â†’ Banco
5. **ğŸŒ Exemplo 04: Ler API Bitcoin** - Integrar dados externos via API

---

## ğŸ“š Detalhamento dos Exemplos

### ğŸ”¥ Exemplo 00: Aquecimento Python

#### `exemplo-00-aquecimento-fundamentos.py`
**Conceito:** Conectar com DataLake (S3/Supabase Storage) e ler Parquet  
**Pergunta de NegÃ³cio:** Como ler dados de um Data Lake usando a API S3?  

**O que vocÃª aprende:**
- Como instalar e importar boto3
- Como criar um cliente S3 para conectar com DataLake
- Como listar arquivos no bucket
- Como baixar arquivos Parquet de Data Lakes
- Como converter Parquet para DataFrame
- AnÃ¡lises bÃ¡sicas com Pandas (head, info, describe, groupby, etc.)
- Por que AWS S3 Ã© o padrÃ£o da indÃºstria (mais de 50% das empresas usam)
- Por que Parquet Ã© ideal para Data Lakes

**Conceitos Python:**
- `import boto3`: biblioteca para trabalhar com S3
- `boto3.client()`: cria cliente S3 (compatÃ­vel com Supabase Storage)
- `s3.list_objects()`: lista arquivos no bucket
- `s3.get_object()`: baixa arquivo do Data Lake
- `pd.read_parquet(io.BytesIO())`: lÃª Parquet da memÃ³ria
- MÃ©todos Pandas: `head()`, `info()`, `describe()`, `value_counts()`, `groupby()`, `nlargest()`, etc.

**Por que Data Lakes sÃ£o importantes?**
- Armazenam grandes volumes de dados (terabytes/petabytes)
- MantÃªm dados em formato original (sem transformaÃ§Ã£o prÃ©via)
- Suportam mÃºltiplos formatos (CSV, Parquet, JSON)
- Escalabilidade horizontal (cresce conforme necessidade)
- Economia de custos (armazenamento barato)

**AWS S3 Ã© o padrÃ£o da indÃºstria:**
- Mais de 50% das empresas usam AWS S3 para Data Lakes
- API padrÃ£o que funciona com mÃºltiplas ferramentas
- CompatÃ­vel com Supabase Storage, MinIO, e outros

**Resultado Esperado:**
- ConexÃ£o estabelecida com Data Lake
- Arquivo Parquet baixado e carregado com sucesso
- Dados convertidos para DataFrame e analisados com Pandas
- CompreensÃ£o da importÃ¢ncia de Data Lakes na indÃºstria

---

### ğŸ—„ï¸ Exemplo 02: Salvar no Banco de Dados

#### `exemplo-02-salvar-banco-dados.py`
**Conceito:** Salvar dados processados no PostgreSQL usando pandas  
**Pergunta de NegÃ³cio:** Como salvar dados processados em um banco PostgreSQL?  

**O que vocÃª aprende:**
- Como conectar com PostgreSQL usando SQLAlchemy
- Como salvar DataFrame em tabela SQL com `df.to_sql()`
- Como ler dados salvos para verificar
- Como executar queries SQL e trazer para pandas
- Como atualizar tabela existente (append)
- Por que pandas serve para ler, processar E salvar dados

**Conceitos Python:**
- `sqlalchemy.create_engine()`: cria engine para PostgreSQL
- `df.to_sql()`: salva DataFrame em tabela SQL
- `pd.read_sql_query()`: executa SQL e retorna DataFrame
- `if_exists`: 'replace' (substitui), 'append' (adiciona), 'fail' (erro)

**Por que salvar no banco?**
- Dados podem ser consultados com SQL
- IntegraÃ§Ã£o com outras ferramentas (BI, dashboards)
- Dados persistentes e seguros
- Permite queries complexas

**Resultado Esperado:**
- Dados salvos no PostgreSQL com sucesso
- Tabela criada e populada
- Dados verificados atravÃ©s de query SQL
- CompreensÃ£o de como Python integra com bancos de dados

---

### ğŸ¯ Exemplo 03: Projeto Completo

#### `exemplo-03-projeto-completo.py`
**Conceito:** Buscar dados de API e salvar no PostgreSQL  
**Pergunta de NegÃ³cio:** Como obter dados de uma API e salvar no banco de dados?  
**O que vocÃª aprende:**
- O que Ã© uma API e por que usar
- Como usar a biblioteca requests
- Como fazer requisiÃ§Ãµes GET para APIs REST
- Como processar dados JSON
- Como salvar dados de API no PostgreSQL
- Pipeline completo: API â†’ Processamento â†’ Banco

**Conceitos Python:**
- `requests.get()`: faz requisiÃ§Ã£o HTTP GET para API
- `response.json()`: converte resposta JSON para dicionÃ¡rio Python
- `response.raise_for_status()`: verifica erros HTTP
- `pd.DataFrame()`: cria DataFrame a partir de dicionÃ¡rio
- `df.to_sql()`: salva DataFrame no PostgreSQL

**O que Ã© uma API?**
- API (Application Programming Interface) = Interface de ProgramaÃ§Ã£o de AplicaÃ§Ãµes
- Forma de COMUNICAR com outros sistemas atravÃ©s da internet
- Python na Engenharia de Dados = COMUNICAR com sistemas externos
- SQL trabalha com dados que JÃ EXISTEM no banco
- Python BUSCA dados de sistemas externos via APIs

**Biblioteca Requests:**
- A forma mais simples de fazer requisiÃ§Ãµes HTTP em Python
- Permite: GET (buscar), POST (enviar), PUT (atualizar), DELETE (deletar)
- Para engenharia de dados, usamos principalmente GET para buscar dados

**Fluxo Completo:**
1. **Extract**: Buscar dados da API do Bitcoin (Coinbase)
2. **Transform**: Processar dados JSON e enriquecer (adicionar timestamp, calcular BRL)
3. **Load**: Salvar dados processados no PostgreSQL

**Resultado Esperado:**
- Dados obtidos da API do Bitcoin com sucesso
- Dados processados e transformados
- Dados salvos na tabela `cotacao_bitcoin` no PostgreSQL
- Pipeline API â†’ Banco funcionando

---


---

## ğŸ“ Como Usar

### 1. Instalar DependÃªncias

```bash
# Criar ambiente virtual (recomendado)
python -m venv venv

# Ativar ambiente virtual
# No Windows:
venv\Scripts\activate
# No Mac/Linux:
source venv/bin/activate

# Instalar dependÃªncias
pip install -r requirements.txt
```

### 2. Executar Exemplos

```bash
# Navegar para diretÃ³rio de exemplos
cd aulas/aula-02-python/exemplos

# ğŸ”¥ EXEMPLO 00: Aquecimento Python
python exemplo-00-aquecimento-fundamentos.py

# ğŸ’¾ EXEMPLO 01: Conectar com DataLake
python exemplo-01-ler-datalake-parquet.py

# ğŸ—„ï¸ EXEMPLO 02: Salvar no Banco de Dados
python exemplo-02-salvar-banco-dados.py

# ğŸ¯ EXEMPLO 03: Projeto Completo (DataLake â†’ Banco)
python exemplo-03-projeto-completo.py

# ğŸŒ EXEMPLO 04: Ler API Bitcoin
python exemplo-04-ler-api-bitcoin.py
```

### 3. Modificar e Experimentar

- Altere os caminhos dos arquivos
- Teste com seus prÃ³prios dados
- Combine conceitos de diferentes exemplos
- Crie seus prÃ³prios scripts

---

## ğŸ“ Checklist de Aprendizado

ApÃ³s fazer todos os exemplos, vocÃª deve ser capaz de:

### ğŸ”¥ Exemplo 00: Aquecimento Python
- [ ] Usar print e f-strings
- [ ] Trabalhar com variÃ¡veis (str, int)
- [ ] Usar listas e dicionÃ¡rios
- [ ] Entender por que dicionÃ¡rios sÃ£o essenciais para dados estruturados
- [ ] Trabalhar com lista de dicionÃ¡rios

### ğŸ’¾ Exemplo 01: Conectar com DataLake
- [ ] Entender o que Ã© um Data Lake
- [ ] Usar boto3 para conectar com S3/Supabase Storage
- [ ] Listar arquivos no bucket
- [ ] Baixar arquivos Parquet de Data Lakes
- [ ] Ler Parquet e converter para DataFrame
- [ ] Fazer anÃ¡lises bÃ¡sicas com Pandas
- [ ] Compreender a importÃ¢ncia de Data Lakes na indÃºstria

### ğŸ—„ï¸ Exemplo 02: Salvar no Banco de Dados
- [ ] Conectar Python com PostgreSQL usando SQLAlchemy
- [ ] Salvar DataFrames em tabelas SQL
- [ ] Executar queries SQL e trazer para pandas
- [ ] Atualizar tabelas existentes (append)

### ğŸ¯ Exemplo 03: Projeto Completo
- [ ] Combinar boto3 + pandas + sqlalchemy
- [ ] Criar pipeline completo DataLake â†’ Banco
- [ ] Entender fluxo EL (Extract, Load)

### ğŸŒ Exemplo 04: Ler API Bitcoin
- [ ] Entender o que Ã© uma API
- [ ] Usar biblioteca requests para fazer requisiÃ§Ãµes HTTP
- [ ] Processar dados JSON de APIs
- [ ] Criar pipeline completo API â†’ Processamento â†’ Banco

---

## ğŸ’¡ Dicas

- **Execute em ordem:** Cada exemplo introduz um conceito novo
- **Modifique:** Tente adaptar os scripts para seus prÃ³prios dados
- **Combine:** Use conceitos de exemplos anteriores em novos contextos
- **Valide:** Sempre verifique se os dados foram carregados corretamente
- **Pratique:** Crie seus prÃ³prios scripts de ingestÃ£o

---

## ğŸ› Troubleshooting

### Erro: "ModuleNotFoundError: No module named 'pandas'"
```bash
pip install pandas
```

### Erro: "FileNotFoundError: vendas.csv"
- Verifique se os arquivos CSV estÃ£o na pasta `data/`
- Verifique o caminho relativo no script

### Erro: "ConnectionError" ao baixar arquivos externos
- Verifique sua conexÃ£o com internet
- Verifique se a URL do arquivo estÃ¡ correta e acessÃ­vel
- Alguns repositÃ³rios podem ter rate limiting - adicione delays entre requisiÃ§Ãµes

### Erro: "sqlite3.OperationalError: no such table"
- Execute primeiro o exemplo que cria o banco
- Verifique se o banco foi criado corretamente

---

## ğŸ¯ PrÃ³ximos Passos

Depois de dominar todos os exemplos:

1. Pratique criando seus prÃ³prios scripts de ingestÃ£o
2. Combine diferentes fontes de dados
3. Automatize processos de coleta de dados
4. Avance para a **Aula 3: Engenharia de Dados**

---

## ğŸ“Š Resumo dos Conceitos por Exemplo

| Exemplo | Conceito Principal | O que vocÃª aprende |
|---------|-------------------|-------------------|
| ğŸ”¥ 00 | Fundamentos Python | VariÃ¡veis, listas, dicionÃ¡rios - base para trabalhar com dados |
| ğŸ’¾ 01 | DataLake (S3/Supabase) | Conectar com Data Lakes, ler Parquet, anÃ¡lises com Pandas |
| ğŸ—„ï¸ 02 | Salvar no PostgreSQL | Conectar Python com banco, salvar DataFrames, queries SQL |
| ğŸ¯ 03 | Projeto Completo | Pipeline completo: DataLake â†’ Banco (EL) |
| ğŸŒ 04 | API Bitcoin â†’ Banco | Consumir APIs REST, processar JSON, salvar no banco |

**Total: 5 exemplos prÃ¡ticos cobrindo todo o fluxo de ingestÃ£o de dados!** ğŸš€

---

## ğŸ”— Recursos Adicionais

- [DocumentaÃ§Ã£o Pandas](https://pandas.pydata.org/docs/)
- [DocumentaÃ§Ã£o Requests](https://requests.readthedocs.io/)
- [DocumentaÃ§Ã£o PyArrow (Parquet)](https://arrow.apache.org/docs/python/)
- [SQLAlchemy Tutorial](https://docs.sqlalchemy.org/en/20/tutorial/)

---

**Boa jornada! ğŸ**

